{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.36651513,  0.52305744,  0.13448867],\n",
       "       [ 0.36651513,  1.        ,  0.72875508,  0.54139736],\n",
       "       [ 0.52305744,  0.72875508,  1.        ,  0.43661098],\n",
       "       [ 0.13448867,  0.54139736,  0.43661098,  1.        ]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = (\n",
    "\"The sky is blue\",\n",
    "\"The sun is bright\",\n",
    "\"The sun in the sky is bright\",\n",
    "\"We can see the shining sun, the bright sun\"\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "print(tfidf_matrix.shape)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# print(tfidf_matrix.toarray())\n",
    "# tfidf_matrix[:1].toarray()\n",
    "cosine_similarity(tfidf_matrix[0:1], tfidf_matrix)\n",
    "cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "with stop words filter\n",
      "tf\n",
      " [[1 1 1 1 1 2]\n",
      " [1 0 1 1 1 2]]\n",
      "tfidf(idf = log(n/k))\n",
      " [[ 0.31661852  0.44499628  0.31661852  0.31661852  0.31661852  0.63323704]\n",
      " [ 0.35355339  0.          0.35355339  0.35355339  0.35355339  0.70710678]]\n",
      "tfidf(idf = log(n/k))\n",
      " [[ 0.31661852  0.44499628  0.31661852  0.31661852  0.31661852  0.63323704]\n",
      " [ 0.35355339  0.          0.35355339  0.35355339  0.35355339  0.70710678]]\n",
      "tfidf(idf = log(n/k)+1)\n",
      " [[ 0.30335434  0.51362355  0.30335434  0.30335434  0.30335434  0.60670868]\n",
      " [ 0.35355339  0.          0.35355339  0.35355339  0.35355339  0.70710678]]\n",
      "\n",
      " without stop words filter\n",
      "tf\n",
      " [[1 1 2 1 1 1 1 1 2 1 1 1]\n",
      " [1 1 1 0 1 1 1 1 2 1 1 1]]\n",
      "tfidf(idf = log(n/k))\n",
      " [[ 0.22956481  0.22956481  0.45912961  0.32264532  0.22956481  0.22956481\n",
      "   0.22956481  0.22956481  0.45912961  0.22956481  0.22956481  0.22956481]\n",
      " [ 0.26726124  0.26726124  0.26726124  0.          0.26726124  0.26726124\n",
      "   0.26726124  0.26726124  0.53452248  0.26726124  0.26726124  0.26726124]]\n",
      "tfidf(idf = log(n/k))\n",
      " [[ 0.22956481  0.22956481  0.45912961  0.32264532  0.22956481  0.22956481\n",
      "   0.22956481  0.22956481  0.45912961  0.22956481  0.22956481  0.22956481]\n",
      " [ 0.26726124  0.26726124  0.26726124  0.          0.26726124  0.26726124\n",
      "   0.26726124  0.26726124  0.53452248  0.26726124  0.26726124  0.26726124]]\n",
      "tfidf(idf = log(n/k)+1)\n",
      " [[ 0.22435545  0.22435545  0.44871089  0.37986679  0.22435545  0.22435545\n",
      "   0.22435545  0.22435545  0.44871089  0.22435545  0.22435545  0.22435545]\n",
      " [ 0.26726124  0.26726124  0.26726124  0.          0.26726124  0.26726124\n",
      "   0.26726124  0.26726124  0.53452248  0.26726124  0.26726124  0.26726124]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import pandas as pd\n",
    "\n",
    "path = 'RawData/train.csv'\n",
    "df_train = pd.read_csv(path)\n",
    "df_train.head()\n",
    "\n",
    "##Test scikit-learn(with stop words filter, without stemming)\n",
    "print('\\nwith stop words filter')\n",
    "count_vect = CountVectorizer(analyzer='word', stop_words='english', strip_accents = 'unicode' )\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', stop_words='english', strip_accents = 'unicode' )\n",
    "\n",
    "# print(count_vect.get_feature_names())\n",
    "# print(count_vect.get_stop_words())\n",
    "# print(count_vect.get_params)\n",
    "\n",
    "# print(count_vect_tfidf.get_feature_names())\n",
    "# print(count_vect_tfidf.get_stop_words())\n",
    "# print(count_vect_tfidf.get_params)\n",
    "\n",
    "\n",
    "X_train_counts = count_vect.fit_transform([df_train['question1'][0],df_train['question2'][0]])\n",
    "print('tf\\n',X_train_counts.toarray())\n",
    "\n",
    "X_train_tfidf = tfidf_vect.fit_transform([df_train['question1'][0],df_train['question2'][0]])\n",
    "print('tfidf(idf = log(n/k))\\n', X_train_tfidf.toarray())\n",
    "\n",
    "# X_train_counts.shape  ##tell you columns and rows in this vector table\n",
    "\n",
    "\n",
    "transformer = TfidfTransformer()  \n",
    "print('tfidf(idf = log(n/k))\\n', transformer.fit_transform(X_train_counts).toarray())    ##input the result of CountVectorizer.fit_transform()\n",
    "\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "print('tfidf(idf = log(n/k)+1)\\n', transformer.fit_transform(X_train_counts).toarray())\n",
    "\n",
    "\n",
    "##Test scikit-learn(without stop words filter, without stemming)\n",
    "print('\\n without stop words filter')\n",
    "count_vect = CountVectorizer(analyzer='word', strip_accents = 'unicode' )   ##The params can be ignore in this case\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', strip_accents = 'unicode' )   ##The params can be ignore in this case\n",
    "\n",
    "X_train_counts = count_vect.fit_transform([df_train['question1'][0],df_train['question2'][0]])\n",
    "print('tf\\n', X_train_counts.toarray())\n",
    "\n",
    "X_train_tfidf = tfidf_vect.fit_transform([df_train['question1'][0],df_train['question2'][0]])\n",
    "print('tfidf(idf = log(n/k))\\n', X_train_tfidf.toarray())\n",
    "\n",
    "# X_train_counts.shape  ##tell you columns and rows in this vector table\n",
    "\n",
    "transformer = TfidfTransformer()  ##idf = log(n/k)\n",
    "print('tfidf(idf = log(n/k))\\n', transformer.fit_transform(X_train_counts).toarray())\n",
    "\n",
    "transformer = TfidfTransformer(smooth_idf=False)    ##idf = log(n/k)+1\n",
    "print('tfidf(idf = log(n/k)+1)\\n', transformer.fit_transform(X_train_counts).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
